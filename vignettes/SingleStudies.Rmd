---
title: "Single studies using CohortMethod"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{Single studies using CohortMethod}
-->

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(CohortMethod)
knitr::opts_chunk$set(
  cache=FALSE,
  comment = "#>",
  error = FALSE,
  tidy = FALSE)
```
# Introduction

This vignette describes how you can use the CohortMethod package to perform a single new-user cohort study. We will walk through all the steps needed to perform an examplar study, and we have selected the well-studied topic of the effect of coxibs versus non-selective NSAIDs on GI bleeding-related hospitalization.

# Installation instructions

Before installing the CohortMethod package make sure you have Java and RTools installed. Java can be downloaded from [www.java.com](http://www.java.com). RTools can be downloaded from [CRAN](http://cran.r-project.org/bin/windows/Rtools/).

The CohortMethod package is maintained in a [Github repository](https://github.com/OHDSI/CohortMethod), and has dependencies on other packages in Github. All these packages can be downloaded and installed from within R using the `devtools` package:

```{r tidy=TRUE,eval=FALSE}
install.packages("devtools")
library(devtools)
install_github("ohdsi/SqlRender") 
install_github("ohdsi/DatabaseConnector") 
install_github("ohdsi/Cyclops") 
install_github("ohdsi/CohortMethod") 
```

Once installed, you can use `library(CohortMethod)` to load the package.

# Configuring the connection to the server

First, we need to tell R how to connect to the server where the data is. CohortMethod uses the DatabaseConnector package, which provides the `createConnectionDetails` package. Type `?createConnectionDetails` for the specific settings required for the various database management systems (DBMS). For example, one might connect to a PostgreSQL database using this code:

```{r tidy=FALSE,eval=FALSE}
connectionDetails <- createConnectionDetails(dbms = "postgresql", 
                                             server = "localhost/ohdsi", 
                                             user = "joe", 
                                             password = "supersecret")

cdmSchema <- "MY_CDM_DATA"
resultsSchema <- "MY_RESULTS"
```

The last two lines define the cdmSchema and resultSchema variables, which we'll use later to tell R where the data in CDM format lives, and where we want to write intermediate and result tables.

# Preparing the exposures and outcome(s)

We need to define the exposures and outcomes for our study. We do this by writing SQL statements against the OMOP Common Data Model that populates a table of events we are interested in. For our example study, we've created a file called *coxibVsNonselVsGiBleed.sql* with the following contents:

```
SELECT * FROM
condition_occurrence
INNER JOIN 
visit_occurrence
ON 
condition_occurrence.visit_occurrence_id = visit_occurrence.visit_occurrence_id
WHERE 
  condition_concept_id IN (SELECT descendant_concept_id FROM concept_ancestor WHERE ancestor_concept_id = 192671)
AND
visit_occurrence.place_of_service_concept_id IN ()
```

We can send these SQL statements to the server from within R using the DatabaseConnector. Instead of pre-specifying the names of the schemas where the CDM data is, and where we can store our results, it is better to make these parameters as shown above. The SqlRender package offers functionality for replacing these parameters with the actual values in R. Furthermore, if we want to make sure others can also run our code even when they are using a different DBMS, we can first translate the SQL to the dialect needed for the server:

```{r tidy=TRUE,eval=FALSE}
sql <- readSql("coxibVsNonselVsGiBleed.sql")
sql <- renderSql(sql,cdmSchema = cdmSchema, resultsSchema = resultsSchema)
sql <- translateSql(sql, targetDialect = connectionDetails$dbms)$sql

connection <- connect(connectionDetails)
executeSql(connection, sql)
```

In this code, we first read the SQL from the file into memory. In the next line, we replace the two parameter names with the actual values. We then translate the SQL into the dialect appropriate for the DBMS we already specified in the connectionDetails. Next, we connect to the server, and submit the (translated) SQL.

If all went well, we now have a table with the events of interest. We can see how many events per type:

```{r tidy=TRUE,eval=FALSE}
sql <- "SELECT cohort_concept_id, COUNT(*) AS count FROM coxibVsNonselVsGiBleed GROUP BY cohort_concept_id"
sql <- translateSql(sql, targetDialect = connectionDetails$dbms)$sql

querySql(connection, sql)
```
```{r echo=FALSE,message=FALSE}
data.frame(cohort_concept_id = c(1,2,3),count=c(11231,123123,222))
```

# Extracting the data from the server

Now we can tell CohortMethod to define the cohorts based on our events, and extract all necessay data for our analysis:

```{r tidy=FALSE,eval=FALSE}
 cohortData <- getDbCohortData(connectionDetails,
                               cdmSchema = cdmSchema,
                               resultsSchema = resultsSchema,
                               targetDrugConceptId = 1,
                               comparatorDrugConceptId = 2, 
                               indicationConceptIds = "",
                               washoutWindow = 183, 
                               indicationLookbackWindow = 183,
                               studyStartDate = "", 
                               studyEndDate = "", 
                               exclusionConceptIds = "",
                               outcomeConceptIds = 3, 
                               outcomeConditionTypeConceptIds = "", 
                               maxOutcomeCount = 1,
                               exposureSchema = resultsSchema,
                               exposureTable = "MDCR_RivaWarfCER_cohort",
                               outcomeSchema = resultsSchema,
                               outcomeTable = "MDCR_RivaWarfCER_cohort",
                               useCovariateDemographics = TRUE, 
                               useCovariateConditionOccurrence = TRUE,
                               useCovariateConditionEra = FALSE, 
                               useCovariateConditionGroup = FALSE,
                               useCovariateDrugExposure = FALSE, 
                               useCovariateDrugEra = FALSE,
                               useCovariateDrugGroup = FALSE, 
                               useCovariateProcedureOccurrence = FALSE,
                               useCovariateProcedureGroup = FALSE, 
                               useCovariateObservation = FALSE,
                               useCovariateConceptCounts = FALSE, 
                               useCovariateRiskScores = FALSE,
                               useCovariateInteractionYear = FALSE, 
                               useCovariateInteractionMonth = FALSE,
                               excludedCovariateConceptIds = "", 
                               deleteCovariatesSmallCount = 100)
```
There are a lot of parameters, but they are all documented in the CohortMethod manual.

```{r echo=FALSE,message=FALSE}
data(cohortDataSimulationProfile)
cohortData <- simulateCohortData(cohortDataSimulationProfile, n=10000)
```

# Fitting a propensity model
